{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyper parameter\n",
    "epoch_num = 80\n",
    "batch_size = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image preprocessing modules\n",
    "transform = transforms.Compose([\n",
    "    transforms.Pad(4), #填充\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32), #随即裁剪\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#data download\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='../../data/',\n",
    "                                             train = True,\n",
    "                                             download=True,\n",
    "                                             transform=transforms.ToTensor())\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='../../data/',\n",
    "                                             train = False,\n",
    "                                             transform=transforms.ToTensor())\n",
    "\n",
    "#data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size = batch_size,\n",
    "                                           shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                           batch_size = batch_size,\n",
    "                                           shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3x3 Conv\n",
    "def conv3x3(in_channels,out_channels,stride = 1): #无偏置的3x3卷积\n",
    "    return nn.Conv2d(in_channels=in_channels,\n",
    "                     out_channels=out_channels,\n",
    "                     kernel_size=3,\n",
    "                     stride=stride,\n",
    "                     padding = 1,\n",
    "                     bias = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual Block\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self,in_channels,out_channels,stride=1,downsample=None):\n",
    "        super(ResidualBlock,self).__init__()\n",
    "        self.conv1 = conv3x3(in_channels,out_channels,stride)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)  #inplace改变输入数据\n",
    "        self.conv2 = conv3x3(out_channels,out_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.downsample = downsample\n",
    "        \n",
    "    def forward(self,x):\n",
    "        residual = x    #skip connection\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        if self.downsample:       #维度变化就要做downsample来对齐\n",
    "            residual = self.downsample(x)\n",
    "        out +=residual\n",
    "        out = self.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ResNet\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self,block,layers,output_size = 10):\n",
    "        super(ResNet,self).__init__()\n",
    "        self.in_channels = 16\n",
    "        self.conv = conv3x3(3,16)\n",
    "        self.bn = nn.BatchNorm2d(16)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.layer1 = self.make_layer(block,16,layers[0])\n",
    "        self.layer2 = self.make_layer(block,32,layers[1],2)\n",
    "        self.layer3 = self.make_layer(block,64,layers[2],2)\n",
    "        self.avg_pool = nn.AvgPool2d(8)\n",
    "        self.fc = nn.Linear(64,output_size)\n",
    "    \n",
    "    def make_layer(self,block,out_channels,blocks,stride=1):\n",
    "        downsample = None\n",
    "        if (stride !=1) or (self.in_channels !=out_channels):\n",
    "            downsample = nn.Sequential(\n",
    "            conv3x3(self.in_channels,out_channels,stride=stride),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "        \n",
    "        layers = []\n",
    "        layers.append(block(self.in_channels,out_channels,stride,downsample))\n",
    "        self.in_channels = out_channels\n",
    "        for i in range(1,blocks):\n",
    "            layers.append(block(out_channels,out_channels))\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        out = self.conv(x)\n",
    "        out = self.bn(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.avg_pool(out)\n",
    "        out = out.view(out.size(0),-1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet(ResidualBlock,[2,2,2]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criterion and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_lr(optimizer,lr): #动态调整学习率\n",
    "    for para_group in optimizer.param_groups:\n",
    "        para_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch=1/80,step=100/500,loss=1.6379\n",
      "Epoch=1/80,step=200/500,loss=1.5276\n",
      "Epoch=1/80,step=300/500,loss=1.3089\n",
      "Epoch=1/80,step=400/500,loss=1.2329\n",
      "Epoch=1/80,step=500/500,loss=1.1730\n",
      "Epoch=2/80,step=100/500,loss=0.9029\n",
      "Epoch=2/80,step=200/500,loss=0.8060\n",
      "Epoch=2/80,step=300/500,loss=1.1179\n",
      "Epoch=2/80,step=400/500,loss=0.8464\n",
      "Epoch=2/80,step=500/500,loss=0.9274\n",
      "Epoch=3/80,step=100/500,loss=0.9064\n",
      "Epoch=3/80,step=200/500,loss=0.7588\n",
      "Epoch=3/80,step=300/500,loss=0.7585\n",
      "Epoch=3/80,step=400/500,loss=0.7004\n",
      "Epoch=3/80,step=500/500,loss=0.7804\n",
      "Epoch=4/80,step=100/500,loss=0.7884\n",
      "Epoch=4/80,step=200/500,loss=0.7157\n",
      "Epoch=4/80,step=300/500,loss=0.7448\n",
      "Epoch=4/80,step=400/500,loss=0.7118\n",
      "Epoch=4/80,step=500/500,loss=0.5978\n",
      "Epoch=5/80,step=100/500,loss=0.6569\n",
      "Epoch=5/80,step=200/500,loss=0.8102\n",
      "Epoch=5/80,step=300/500,loss=0.6100\n",
      "Epoch=5/80,step=400/500,loss=0.7112\n",
      "Epoch=5/80,step=500/500,loss=0.5863\n",
      "Epoch=6/80,step=100/500,loss=0.4922\n",
      "Epoch=6/80,step=200/500,loss=0.6558\n",
      "Epoch=6/80,step=300/500,loss=0.6659\n",
      "Epoch=6/80,step=400/500,loss=0.5180\n",
      "Epoch=6/80,step=500/500,loss=0.4245\n",
      "Epoch=7/80,step=100/500,loss=0.3889\n",
      "Epoch=7/80,step=200/500,loss=0.3832\n",
      "Epoch=7/80,step=300/500,loss=0.6564\n",
      "Epoch=7/80,step=400/500,loss=0.6034\n",
      "Epoch=7/80,step=500/500,loss=0.5297\n",
      "Epoch=8/80,step=100/500,loss=0.5799\n",
      "Epoch=8/80,step=200/500,loss=0.5458\n",
      "Epoch=8/80,step=300/500,loss=0.3845\n",
      "Epoch=8/80,step=400/500,loss=0.5937\n",
      "Epoch=8/80,step=500/500,loss=0.4632\n",
      "Epoch=9/80,step=100/500,loss=0.2977\n",
      "Epoch=9/80,step=200/500,loss=0.4283\n",
      "Epoch=9/80,step=300/500,loss=0.4643\n",
      "Epoch=9/80,step=400/500,loss=0.6120\n",
      "Epoch=9/80,step=500/500,loss=0.7234\n",
      "Epoch=10/80,step=100/500,loss=0.2952\n",
      "Epoch=10/80,step=200/500,loss=0.2792\n",
      "Epoch=10/80,step=300/500,loss=0.4151\n",
      "Epoch=10/80,step=400/500,loss=0.2667\n",
      "Epoch=10/80,step=500/500,loss=0.4173\n",
      "Epoch=11/80,step=100/500,loss=0.3314\n",
      "Epoch=11/80,step=200/500,loss=0.2586\n",
      "Epoch=11/80,step=300/500,loss=0.3909\n",
      "Epoch=11/80,step=400/500,loss=0.4004\n",
      "Epoch=11/80,step=500/500,loss=0.3718\n",
      "Epoch=12/80,step=100/500,loss=0.1830\n",
      "Epoch=12/80,step=200/500,loss=0.3009\n",
      "Epoch=12/80,step=300/500,loss=0.3806\n",
      "Epoch=12/80,step=400/500,loss=0.3041\n",
      "Epoch=12/80,step=500/500,loss=0.3512\n",
      "Epoch=13/80,step=100/500,loss=0.2948\n",
      "Epoch=13/80,step=200/500,loss=0.3243\n",
      "Epoch=13/80,step=300/500,loss=0.2832\n",
      "Epoch=13/80,step=400/500,loss=0.2295\n",
      "Epoch=13/80,step=500/500,loss=0.2381\n",
      "Epoch=14/80,step=100/500,loss=0.1975\n",
      "Epoch=14/80,step=200/500,loss=0.1401\n",
      "Epoch=14/80,step=300/500,loss=0.1840\n",
      "Epoch=14/80,step=400/500,loss=0.3810\n",
      "Epoch=14/80,step=500/500,loss=0.1263\n",
      "Epoch=15/80,step=100/500,loss=0.1612\n",
      "Epoch=15/80,step=200/500,loss=0.2081\n",
      "Epoch=15/80,step=300/500,loss=0.2457\n",
      "Epoch=15/80,step=400/500,loss=0.2858\n",
      "Epoch=15/80,step=500/500,loss=0.3381\n",
      "Epoch=16/80,step=100/500,loss=0.2344\n",
      "Epoch=16/80,step=200/500,loss=0.2235\n",
      "Epoch=16/80,step=300/500,loss=0.2258\n",
      "Epoch=16/80,step=400/500,loss=0.1654\n",
      "Epoch=16/80,step=500/500,loss=0.2169\n",
      "Epoch=17/80,step=100/500,loss=0.0726\n",
      "Epoch=17/80,step=200/500,loss=0.1762\n",
      "Epoch=17/80,step=300/500,loss=0.1548\n",
      "Epoch=17/80,step=400/500,loss=0.1650\n",
      "Epoch=17/80,step=500/500,loss=0.1901\n",
      "Epoch=18/80,step=100/500,loss=0.0943\n",
      "Epoch=18/80,step=200/500,loss=0.1139\n",
      "Epoch=18/80,step=300/500,loss=0.2208\n",
      "Epoch=18/80,step=400/500,loss=0.2088\n",
      "Epoch=18/80,step=500/500,loss=0.1555\n",
      "Epoch=19/80,step=100/500,loss=0.1144\n",
      "Epoch=19/80,step=200/500,loss=0.1016\n",
      "Epoch=19/80,step=300/500,loss=0.2182\n",
      "Epoch=19/80,step=400/500,loss=0.1269\n",
      "Epoch=19/80,step=500/500,loss=0.1448\n",
      "Epoch=20/80,step=100/500,loss=0.1430\n",
      "Epoch=20/80,step=200/500,loss=0.1409\n",
      "Epoch=20/80,step=300/500,loss=0.1429\n",
      "Epoch=20/80,step=400/500,loss=0.2178\n",
      "Epoch=20/80,step=500/500,loss=0.1719\n",
      "Epoch=21/80,step=100/500,loss=0.0833\n",
      "Epoch=21/80,step=200/500,loss=0.0594\n",
      "Epoch=21/80,step=300/500,loss=0.0788\n",
      "Epoch=21/80,step=400/500,loss=0.0297\n",
      "Epoch=21/80,step=500/500,loss=0.0596\n",
      "Epoch=22/80,step=100/500,loss=0.0485\n",
      "Epoch=22/80,step=200/500,loss=0.0318\n",
      "Epoch=22/80,step=300/500,loss=0.0210\n",
      "Epoch=22/80,step=400/500,loss=0.0291\n",
      "Epoch=22/80,step=500/500,loss=0.0485\n",
      "Epoch=23/80,step=100/500,loss=0.0237\n",
      "Epoch=23/80,step=200/500,loss=0.0269\n",
      "Epoch=23/80,step=300/500,loss=0.0327\n",
      "Epoch=23/80,step=400/500,loss=0.0168\n",
      "Epoch=23/80,step=500/500,loss=0.0489\n",
      "Epoch=24/80,step=100/500,loss=0.0144\n",
      "Epoch=24/80,step=200/500,loss=0.0354\n",
      "Epoch=24/80,step=300/500,loss=0.0428\n",
      "Epoch=24/80,step=400/500,loss=0.0199\n",
      "Epoch=24/80,step=500/500,loss=0.0191\n",
      "Epoch=25/80,step=100/500,loss=0.0122\n",
      "Epoch=25/80,step=200/500,loss=0.0224\n",
      "Epoch=25/80,step=300/500,loss=0.0147\n",
      "Epoch=25/80,step=400/500,loss=0.0165\n",
      "Epoch=25/80,step=500/500,loss=0.0232\n",
      "Epoch=26/80,step=100/500,loss=0.0105\n",
      "Epoch=26/80,step=200/500,loss=0.0285\n",
      "Epoch=26/80,step=300/500,loss=0.0376\n",
      "Epoch=26/80,step=400/500,loss=0.0467\n",
      "Epoch=26/80,step=500/500,loss=0.0363\n",
      "Epoch=27/80,step=100/500,loss=0.0112\n",
      "Epoch=27/80,step=200/500,loss=0.0364\n",
      "Epoch=27/80,step=300/500,loss=0.0090\n",
      "Epoch=27/80,step=400/500,loss=0.0355\n",
      "Epoch=27/80,step=500/500,loss=0.0098\n",
      "Epoch=28/80,step=100/500,loss=0.0051\n",
      "Epoch=28/80,step=200/500,loss=0.0041\n",
      "Epoch=28/80,step=300/500,loss=0.0206\n",
      "Epoch=28/80,step=400/500,loss=0.0033\n",
      "Epoch=28/80,step=500/500,loss=0.0335\n",
      "Epoch=29/80,step=100/500,loss=0.0054\n",
      "Epoch=29/80,step=200/500,loss=0.0048\n",
      "Epoch=29/80,step=300/500,loss=0.0144\n",
      "Epoch=29/80,step=400/500,loss=0.0088\n",
      "Epoch=29/80,step=500/500,loss=0.0559\n",
      "Epoch=30/80,step=100/500,loss=0.0596\n",
      "Epoch=30/80,step=200/500,loss=0.0192\n",
      "Epoch=30/80,step=300/500,loss=0.0065\n",
      "Epoch=30/80,step=400/500,loss=0.0373\n",
      "Epoch=30/80,step=500/500,loss=0.0079\n",
      "Epoch=31/80,step=100/500,loss=0.0121\n",
      "Epoch=31/80,step=200/500,loss=0.0127\n",
      "Epoch=31/80,step=300/500,loss=0.0192\n",
      "Epoch=31/80,step=400/500,loss=0.0191\n",
      "Epoch=31/80,step=500/500,loss=0.0337\n",
      "Epoch=32/80,step=100/500,loss=0.0089\n",
      "Epoch=32/80,step=200/500,loss=0.0115\n",
      "Epoch=32/80,step=300/500,loss=0.0047\n",
      "Epoch=32/80,step=400/500,loss=0.0177\n",
      "Epoch=32/80,step=500/500,loss=0.0128\n",
      "Epoch=33/80,step=100/500,loss=0.0095\n",
      "Epoch=33/80,step=200/500,loss=0.0109\n",
      "Epoch=33/80,step=300/500,loss=0.0118\n",
      "Epoch=33/80,step=400/500,loss=0.0163\n",
      "Epoch=33/80,step=500/500,loss=0.0164\n",
      "Epoch=34/80,step=100/500,loss=0.0040\n",
      "Epoch=34/80,step=200/500,loss=0.0058\n",
      "Epoch=34/80,step=300/500,loss=0.0037\n",
      "Epoch=34/80,step=400/500,loss=0.0108\n",
      "Epoch=34/80,step=500/500,loss=0.0395\n",
      "Epoch=35/80,step=100/500,loss=0.0144\n",
      "Epoch=35/80,step=200/500,loss=0.0134\n",
      "Epoch=35/80,step=300/500,loss=0.0107\n",
      "Epoch=35/80,step=400/500,loss=0.0059\n",
      "Epoch=35/80,step=500/500,loss=0.0046\n",
      "Epoch=36/80,step=100/500,loss=0.0045\n",
      "Epoch=36/80,step=200/500,loss=0.0277\n",
      "Epoch=36/80,step=300/500,loss=0.0222\n",
      "Epoch=36/80,step=400/500,loss=0.0326\n",
      "Epoch=36/80,step=500/500,loss=0.0158\n",
      "Epoch=37/80,step=100/500,loss=0.0050\n",
      "Epoch=37/80,step=200/500,loss=0.0297\n",
      "Epoch=37/80,step=300/500,loss=0.0117\n",
      "Epoch=37/80,step=400/500,loss=0.0061\n",
      "Epoch=37/80,step=500/500,loss=0.0065\n",
      "Epoch=38/80,step=100/500,loss=0.0062\n",
      "Epoch=38/80,step=200/500,loss=0.0079\n",
      "Epoch=38/80,step=300/500,loss=0.0578\n",
      "Epoch=38/80,step=400/500,loss=0.0105\n",
      "Epoch=38/80,step=500/500,loss=0.0061\n",
      "Epoch=39/80,step=100/500,loss=0.0335\n",
      "Epoch=39/80,step=200/500,loss=0.0114\n",
      "Epoch=39/80,step=300/500,loss=0.0092\n",
      "Epoch=39/80,step=400/500,loss=0.0020\n",
      "Epoch=39/80,step=500/500,loss=0.0095\n",
      "Epoch=40/80,step=100/500,loss=0.0042\n",
      "Epoch=40/80,step=200/500,loss=0.0033\n",
      "Epoch=40/80,step=300/500,loss=0.0476\n",
      "Epoch=40/80,step=400/500,loss=0.0019\n",
      "Epoch=40/80,step=500/500,loss=0.0185\n",
      "Epoch=41/80,step=100/500,loss=0.0040\n",
      "Epoch=41/80,step=200/500,loss=0.0082\n",
      "Epoch=41/80,step=300/500,loss=0.0050\n",
      "Epoch=41/80,step=400/500,loss=0.0044\n",
      "Epoch=41/80,step=500/500,loss=0.0009\n",
      "Epoch=42/80,step=100/500,loss=0.0012\n",
      "Epoch=42/80,step=200/500,loss=0.0029\n",
      "Epoch=42/80,step=300/500,loss=0.0016\n",
      "Epoch=42/80,step=400/500,loss=0.0028\n",
      "Epoch=42/80,step=500/500,loss=0.0095\n",
      "Epoch=43/80,step=100/500,loss=0.0022\n",
      "Epoch=43/80,step=200/500,loss=0.0039\n",
      "Epoch=43/80,step=300/500,loss=0.0076\n",
      "Epoch=43/80,step=400/500,loss=0.0091\n",
      "Epoch=43/80,step=500/500,loss=0.0041\n",
      "Epoch=44/80,step=100/500,loss=0.0028\n",
      "Epoch=44/80,step=200/500,loss=0.0012\n",
      "Epoch=44/80,step=300/500,loss=0.0024\n",
      "Epoch=44/80,step=400/500,loss=0.0068\n",
      "Epoch=44/80,step=500/500,loss=0.0024\n",
      "Epoch=45/80,step=100/500,loss=0.0027\n",
      "Epoch=45/80,step=200/500,loss=0.0015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch=45/80,step=300/500,loss=0.0028\n",
      "Epoch=45/80,step=400/500,loss=0.0012\n",
      "Epoch=45/80,step=500/500,loss=0.0007\n",
      "Epoch=46/80,step=100/500,loss=0.0004\n",
      "Epoch=46/80,step=200/500,loss=0.0005\n",
      "Epoch=46/80,step=300/500,loss=0.0011\n",
      "Epoch=46/80,step=400/500,loss=0.0018\n",
      "Epoch=46/80,step=500/500,loss=0.0006\n",
      "Epoch=47/80,step=100/500,loss=0.0019\n",
      "Epoch=47/80,step=200/500,loss=0.0008\n",
      "Epoch=47/80,step=300/500,loss=0.0026\n",
      "Epoch=47/80,step=400/500,loss=0.0015\n",
      "Epoch=47/80,step=500/500,loss=0.0005\n",
      "Epoch=48/80,step=100/500,loss=0.0009\n",
      "Epoch=48/80,step=200/500,loss=0.0017\n",
      "Epoch=48/80,step=300/500,loss=0.0041\n",
      "Epoch=48/80,step=400/500,loss=0.0013\n",
      "Epoch=48/80,step=500/500,loss=0.0043\n",
      "Epoch=49/80,step=100/500,loss=0.0017\n",
      "Epoch=49/80,step=200/500,loss=0.0016\n",
      "Epoch=49/80,step=300/500,loss=0.0010\n",
      "Epoch=49/80,step=400/500,loss=0.0006\n",
      "Epoch=49/80,step=500/500,loss=0.0004\n",
      "Epoch=50/80,step=100/500,loss=0.0008\n",
      "Epoch=50/80,step=200/500,loss=0.0064\n",
      "Epoch=50/80,step=300/500,loss=0.0015\n",
      "Epoch=50/80,step=400/500,loss=0.0053\n",
      "Epoch=50/80,step=500/500,loss=0.0009\n",
      "Epoch=51/80,step=100/500,loss=0.0006\n",
      "Epoch=51/80,step=200/500,loss=0.0019\n",
      "Epoch=51/80,step=300/500,loss=0.0012\n",
      "Epoch=51/80,step=400/500,loss=0.0025\n",
      "Epoch=51/80,step=500/500,loss=0.0015\n",
      "Epoch=52/80,step=100/500,loss=0.0007\n",
      "Epoch=52/80,step=200/500,loss=0.0006\n",
      "Epoch=52/80,step=300/500,loss=0.0008\n",
      "Epoch=52/80,step=400/500,loss=0.0002\n",
      "Epoch=52/80,step=500/500,loss=0.0036\n",
      "Epoch=53/80,step=100/500,loss=0.0001\n",
      "Epoch=53/80,step=200/500,loss=0.0019\n",
      "Epoch=53/80,step=300/500,loss=0.0029\n",
      "Epoch=53/80,step=400/500,loss=0.0008\n",
      "Epoch=53/80,step=500/500,loss=0.0010\n",
      "Epoch=54/80,step=100/500,loss=0.0013\n",
      "Epoch=54/80,step=200/500,loss=0.0011\n",
      "Epoch=54/80,step=300/500,loss=0.0007\n",
      "Epoch=54/80,step=400/500,loss=0.0029\n",
      "Epoch=54/80,step=500/500,loss=0.0009\n",
      "Epoch=55/80,step=100/500,loss=0.0016\n",
      "Epoch=55/80,step=200/500,loss=0.0004\n",
      "Epoch=55/80,step=300/500,loss=0.0074\n",
      "Epoch=55/80,step=400/500,loss=0.0021\n",
      "Epoch=55/80,step=500/500,loss=0.0028\n",
      "Epoch=56/80,step=100/500,loss=0.0019\n",
      "Epoch=56/80,step=200/500,loss=0.0030\n",
      "Epoch=56/80,step=300/500,loss=0.0029\n",
      "Epoch=56/80,step=400/500,loss=0.0013\n",
      "Epoch=56/80,step=500/500,loss=0.0011\n",
      "Epoch=57/80,step=100/500,loss=0.0003\n",
      "Epoch=57/80,step=200/500,loss=0.0005\n",
      "Epoch=57/80,step=300/500,loss=0.0015\n",
      "Epoch=57/80,step=400/500,loss=0.0007\n",
      "Epoch=57/80,step=500/500,loss=0.0014\n",
      "Epoch=58/80,step=100/500,loss=0.0014\n",
      "Epoch=58/80,step=200/500,loss=0.0004\n",
      "Epoch=58/80,step=300/500,loss=0.0043\n",
      "Epoch=58/80,step=400/500,loss=0.0083\n",
      "Epoch=58/80,step=500/500,loss=0.0021\n",
      "Epoch=59/80,step=100/500,loss=0.0034\n",
      "Epoch=59/80,step=200/500,loss=0.0017\n",
      "Epoch=59/80,step=300/500,loss=0.0005\n",
      "Epoch=59/80,step=400/500,loss=0.0037\n",
      "Epoch=59/80,step=500/500,loss=0.0007\n",
      "Epoch=60/80,step=100/500,loss=0.0014\n",
      "Epoch=60/80,step=200/500,loss=0.0006\n",
      "Epoch=60/80,step=300/500,loss=0.0092\n",
      "Epoch=60/80,step=400/500,loss=0.0004\n",
      "Epoch=60/80,step=500/500,loss=0.0009\n",
      "Epoch=61/80,step=100/500,loss=0.0017\n",
      "Epoch=61/80,step=200/500,loss=0.0007\n",
      "Epoch=61/80,step=300/500,loss=0.0007\n",
      "Epoch=61/80,step=400/500,loss=0.0006\n",
      "Epoch=61/80,step=500/500,loss=0.0008\n",
      "Epoch=62/80,step=100/500,loss=0.0008\n",
      "Epoch=62/80,step=200/500,loss=0.0016\n",
      "Epoch=62/80,step=300/500,loss=0.0006\n",
      "Epoch=62/80,step=400/500,loss=0.0007\n",
      "Epoch=62/80,step=500/500,loss=0.0005\n",
      "Epoch=63/80,step=100/500,loss=0.0001\n",
      "Epoch=63/80,step=200/500,loss=0.0008\n",
      "Epoch=63/80,step=300/500,loss=0.0019\n",
      "Epoch=63/80,step=400/500,loss=0.0007\n",
      "Epoch=63/80,step=500/500,loss=0.0004\n",
      "Epoch=64/80,step=100/500,loss=0.0004\n",
      "Epoch=64/80,step=200/500,loss=0.0008\n",
      "Epoch=64/80,step=300/500,loss=0.0004\n",
      "Epoch=64/80,step=400/500,loss=0.0001\n",
      "Epoch=64/80,step=500/500,loss=0.0004\n",
      "Epoch=65/80,step=100/500,loss=0.0004\n",
      "Epoch=65/80,step=200/500,loss=0.0004\n",
      "Epoch=65/80,step=300/500,loss=0.0005\n",
      "Epoch=65/80,step=400/500,loss=0.0003\n",
      "Epoch=65/80,step=500/500,loss=0.0004\n",
      "Epoch=66/80,step=100/500,loss=0.0002\n",
      "Epoch=66/80,step=200/500,loss=0.0002\n",
      "Epoch=66/80,step=300/500,loss=0.0001\n",
      "Epoch=66/80,step=400/500,loss=0.0004\n",
      "Epoch=66/80,step=500/500,loss=0.0004\n",
      "Epoch=67/80,step=100/500,loss=0.0006\n",
      "Epoch=67/80,step=200/500,loss=0.0014\n",
      "Epoch=67/80,step=300/500,loss=0.0002\n",
      "Epoch=67/80,step=400/500,loss=0.0003\n",
      "Epoch=67/80,step=500/500,loss=0.0006\n",
      "Epoch=68/80,step=100/500,loss=0.0005\n",
      "Epoch=68/80,step=200/500,loss=0.0024\n",
      "Epoch=68/80,step=300/500,loss=0.0005\n",
      "Epoch=68/80,step=400/500,loss=0.0002\n",
      "Epoch=68/80,step=500/500,loss=0.0002\n",
      "Epoch=69/80,step=100/500,loss=0.0029\n",
      "Epoch=69/80,step=200/500,loss=0.0006\n",
      "Epoch=69/80,step=300/500,loss=0.0003\n",
      "Epoch=69/80,step=400/500,loss=0.0003\n",
      "Epoch=69/80,step=500/500,loss=0.0010\n",
      "Epoch=70/80,step=100/500,loss=0.0006\n",
      "Epoch=70/80,step=200/500,loss=0.0010\n",
      "Epoch=70/80,step=300/500,loss=0.0001\n",
      "Epoch=70/80,step=400/500,loss=0.0007\n",
      "Epoch=70/80,step=500/500,loss=0.0010\n",
      "Epoch=71/80,step=100/500,loss=0.0009\n",
      "Epoch=71/80,step=200/500,loss=0.0002\n",
      "Epoch=71/80,step=300/500,loss=0.0005\n",
      "Epoch=71/80,step=400/500,loss=0.0003\n",
      "Epoch=71/80,step=500/500,loss=0.0002\n",
      "Epoch=72/80,step=100/500,loss=0.0002\n",
      "Epoch=72/80,step=200/500,loss=0.0003\n",
      "Epoch=72/80,step=300/500,loss=0.0005\n",
      "Epoch=72/80,step=400/500,loss=0.0001\n",
      "Epoch=72/80,step=500/500,loss=0.0003\n",
      "Epoch=73/80,step=100/500,loss=0.0004\n",
      "Epoch=73/80,step=200/500,loss=0.0006\n",
      "Epoch=73/80,step=300/500,loss=0.0002\n",
      "Epoch=73/80,step=400/500,loss=0.0002\n",
      "Epoch=73/80,step=500/500,loss=0.0004\n",
      "Epoch=74/80,step=100/500,loss=0.0002\n",
      "Epoch=74/80,step=200/500,loss=0.0002\n",
      "Epoch=74/80,step=300/500,loss=0.0001\n",
      "Epoch=74/80,step=400/500,loss=0.0004\n",
      "Epoch=74/80,step=500/500,loss=0.0009\n",
      "Epoch=75/80,step=100/500,loss=0.0008\n",
      "Epoch=75/80,step=200/500,loss=0.0002\n",
      "Epoch=75/80,step=300/500,loss=0.0013\n",
      "Epoch=75/80,step=400/500,loss=0.0001\n",
      "Epoch=75/80,step=500/500,loss=0.0001\n",
      "Epoch=76/80,step=100/500,loss=0.0005\n",
      "Epoch=76/80,step=200/500,loss=0.0003\n",
      "Epoch=76/80,step=300/500,loss=0.0001\n",
      "Epoch=76/80,step=400/500,loss=0.0011\n",
      "Epoch=76/80,step=500/500,loss=0.0002\n",
      "Epoch=77/80,step=100/500,loss=0.0007\n",
      "Epoch=77/80,step=200/500,loss=0.0003\n",
      "Epoch=77/80,step=300/500,loss=0.0003\n",
      "Epoch=77/80,step=400/500,loss=0.0001\n",
      "Epoch=77/80,step=500/500,loss=0.0004\n",
      "Epoch=78/80,step=100/500,loss=0.0002\n",
      "Epoch=78/80,step=200/500,loss=0.0002\n",
      "Epoch=78/80,step=300/500,loss=0.0003\n",
      "Epoch=78/80,step=400/500,loss=0.0002\n",
      "Epoch=78/80,step=500/500,loss=0.0011\n",
      "Epoch=79/80,step=100/500,loss=0.0004\n",
      "Epoch=79/80,step=200/500,loss=0.0006\n",
      "Epoch=79/80,step=300/500,loss=0.0003\n",
      "Epoch=79/80,step=400/500,loss=0.0004\n",
      "Epoch=79/80,step=500/500,loss=0.0003\n",
      "Epoch=80/80,step=100/500,loss=0.0007\n",
      "Epoch=80/80,step=200/500,loss=0.0001\n",
      "Epoch=80/80,step=300/500,loss=0.0026\n",
      "Epoch=80/80,step=400/500,loss=0.0003\n",
      "Epoch=80/80,step=500/500,loss=0.0006\n"
     ]
    }
   ],
   "source": [
    "#train model\n",
    "total_step = len(train_loader)\n",
    "cur_lr = learning_rate\n",
    "for epoch in range(epoch_num):\n",
    "    for i,(images,labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        #forward\n",
    "        predict = model(images)\n",
    "        loss = criterion(predict,labels)\n",
    "        \n",
    "        #backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print(\"Epoch={}/{},step={}/{},loss={:.4f}\".format(epoch+1,epoch_num,i+1,total_step,loss.item()) )\n",
    "    \n",
    "    if(epoch+1) % 20 == 0:\n",
    "        cur_lr /= 3\n",
    "        update_lr(optimizer,cur_lr)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is:0.8162\n"
     ]
    }
   ],
   "source": [
    "#test model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images,labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        pred = model(images)\n",
    "        _,pred_pos = torch.max(pred.data,1)\n",
    "        \n",
    "        correct += (pred_pos == labels).sum().item()\n",
    "        total += labels.shape[0]\n",
    "    \n",
    "    print('accuracy is:{:.4f}'.format( (correct/total)   ))\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model\n",
    "torch.save(model.state_dict(),'resnet.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
